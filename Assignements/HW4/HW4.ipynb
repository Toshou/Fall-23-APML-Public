{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6817de-52ff-461b-9ae6-06067db8fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from  torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os, random,sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59809b-debf-4140-8ce2-9b762e63682c",
   "metadata": {},
   "source": [
    "# Build a Variational Autoencoder (VAE) for a human face dataset\n",
    "\n",
    "We will use a dataset containing images of people and train a variational autoencoder on it. \n",
    "\n",
    "## Step 1\n",
    "\n",
    "Download and unzip the ``lfw.zip`` file . Adjust the ``path`` variable so that it contains the address of the unzipped folder. We will create a dataloader from this folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cd50d1-ccc1-45ea-8762-b11a58807347",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/path/to/folder/lfw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d165364-c1e8-4f47-8e8c-2e8149b83606",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform    = transforms.Compose([transforms.ToTensor()]) \n",
    "dataloader = DataLoader(ImageFolder(path, transform,),batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a61e3-03f9-42cb-921f-a75b310d4af4",
   "metadata": {},
   "source": [
    "This project is compute intensive. If you have a cuda or mps device on your laptop make sure you use that in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90672057-0317-4f19-a77d-df65c43fd481",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a48c1-c834-4b95-a0b8-da19d6d293f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in dataloader:\n",
    "    x = x[0].permute(1, 2, 0)\n",
    "    print(x.shape)\n",
    "    plt.imshow(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da87423-ffb1-4abb-a138-b9ed56ae1101",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "The basis for this project is that you can alter your implementation of AutoEncoders from the previous homework and add the necessary bits for a VAE.  Clearly state what is the difference between AutoEncoders and VAEs in terms of Applications, Architecture and Loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38206b5b-becb-4e1e-afc7-fd3234eb3a4d",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "Update your pytorch autoencoder model class to create your VAE. Assume the encoder produces the mean and log variance of the latent space.  \n",
    "\n",
    "**Create separate functions for the encoder and decoder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "09100ae9-3a75-461a-a4f6-ce03d85d9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    def encoder(self,x):\n",
    "        \n",
    "        \n",
    "    def decoder(self,x):\n",
    "\n",
    "       \n",
    "    def forward(self,x):\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e2bf3-5f23-47c2-a230-39022e9d24d2",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Create an instance of the new class, pass an image to the model\n",
    "\n",
    "*  print the shape of the output of the **encoder**. Explain how would you generate new samples in the latent space. Your explanation should show that you have understood the concepts. Providing just the formula or code snippet without context will not earn any points.\n",
    "*  use the decoder to create new images. Print the shape of the output and verify that the forward pass is working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d97cb077-a104-4026-bb3e-8de82f28b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7368281a-fe20-4fd7-b6f1-24fcb6a4b8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace2e6fa-e96b-4e31-b95e-4ad5d694c78d",
   "metadata": {},
   "source": [
    "##  Step 5\n",
    "* Print the total number of parameters in the model\n",
    "* Explain what loss should be used here. Describe in your own words the terms of the loss function and what goal each term of the loss function achieves. Your explanation should show that you have understood the concepts. Providing just the formula or code snippet without context will not earn any points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670cb77-129e-4c1d-ad19-3f6813502a48",
   "metadata": {},
   "source": [
    "* create an optimizer for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "16ca8ac7-7ef8-43de-b284-88320fc79ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a6f49-795a-4be9-a3ec-4460c93d7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eea30d-bbc3-4145-9522-884a08fa093b",
   "metadata": {},
   "source": [
    "##  Step 6\n",
    "Write a training loop and start training the model for several epochs. Report the loss value at the end of each epoch and monitor it. If your loss is not decreasing what do you have to do to troubleshoot it ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc1c21-db79-4742-a00a-ceac8fa8bfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a35665e3-b244-48ed-b0f9-ea0b521df93e",
   "metadata": {},
   "source": [
    "##  Step 7\n",
    "\n",
    "Take a random image from the dataset and plot it together with new samples generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2ed64-4c61-4323-800e-e031bffedf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6905caa-e8b5-4b35-a14a-e39b7ed70371",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
